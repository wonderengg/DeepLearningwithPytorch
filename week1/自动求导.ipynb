{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"自动求导.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMLwv4mTgHKylMpBmRpmcdH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["假设想对函数y=2xTx 关于列向量x求导"],"metadata":{"id":"jPrt6ViUATyz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjPlc4QWAOmQ","executionInfo":{"status":"ok","timestamp":1656817835713,"user_tz":-480,"elapsed":354,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"5e6a0380-6918-49f4-8cd7-ed4eb975dd33"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.])"]},"metadata":{},"execution_count":7}],"source":["import torch\n","\n","x = torch.arange(4.0)\n","x"]},{"cell_type":"code","source":["x.requires_grad_(True) #等价于x = torch.arange(4.0,requires_grad=True)\n","x.grad #默认值是none"],"metadata":{"id":"1Nl4oEcFAsK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = 2*torch.dot(x,x)\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DlbX-BwbBZvo","executionInfo":{"status":"ok","timestamp":1656817838080,"user_tz":-480,"elapsed":512,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"d09b7db4-d77d-4efc-e328-cbb1bd054f07"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(28., grad_fn=<MulBackward0>)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["通过调用反向传播函数来自动计算y关于x每个分量的梯度"],"metadata":{"id":"W6BXNLtXBrX0"}},{"cell_type":"code","source":["y.backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2p-siQEkBiH0","executionInfo":{"status":"ok","timestamp":1656817840415,"user_tz":-480,"elapsed":355,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"d3c6d7eb-fd42-458e-97ac-1c779a5032ec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.,  4.,  8., 12.])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["x.grad == 4*x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7_6k5rjB1s8","executionInfo":{"status":"ok","timestamp":1656817843281,"user_tz":-480,"elapsed":372,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"4d575ee8-7739-44e7-944d-e01138ad23e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#默认情况下，pytorch会累积梯度，我们需要清楚之前的值\n","x.grad.zero_()\n","y = x.sum()\n","y.backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SvEZzKIB_Hx","executionInfo":{"status":"ok","timestamp":1656817858010,"user_tz":-480,"elapsed":4,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"6d56504f-e16f-4910-eb67-a5a50cb1c85f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 1., 1., 1.])"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["在深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和"],"metadata":{"id":"-xEi8A6eC7VN"}},{"cell_type":"code","source":["#对非标量用backward需要传入一个gradient参数\n","x.grad.zero_()\n","y = x * x\n","#等价于y.backward(torch.ones(len(x))\n","y.sum().backward()\n","x.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dz-2VLAUCZBM","executionInfo":{"status":"ok","timestamp":1656818160522,"user_tz":-480,"elapsed":8,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"17f0128f-d445-4d96-9746-c5c472040fa2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 2., 4., 6.])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["x.grad.zero_()\n","y = x * x\n","u = y.detach() #把y当做一个常数而不是x的函数，即对系统来讲u的值就等于x*x\n","z = u * x \n","\n","z.sum().backward()\n","x.grad == u"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ti6OWMipDs8D","executionInfo":{"status":"ok","timestamp":1656818344139,"user_tz":-480,"elapsed":8,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"fe3cab9a-583d-484d-8261-0038484b7913"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["x.grad.zero_()\n","y.sum().backward()\n","x.grad == 2 * x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1214St_xEZvR","executionInfo":{"status":"ok","timestamp":1656818471859,"user_tz":-480,"elapsed":5,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"480fe20c-1d51-4b9c-84df-d9fd204c6495"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([True, True, True, True])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["即使构建函数的计算图需要通过python控制流（例如，条件、循环或者任意函数调用），我们仍然可以计算得到变量的梯度"],"metadata":{"id":"vpZm_fwOFsx9"}},{"cell_type":"code","source":["def f(a):\n","  b = a * 2\n","  while b.norm() < 1000:\n","    b = b * 2\n","  if b.sum() > 0:\n","    c = b\n","  else:\n","    c = 100 * b\n","  return c\n","\n","a = torch.randn(size=(),requires_grad=True) #size是空的话意思是标量\n","d = f(a)\n","d.backward()\n","\n","a.grad == d / a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9hmblsaE49S","executionInfo":{"status":"ok","timestamp":1656818670574,"user_tz":-480,"elapsed":366,"user":{"displayName":"下垣鳴海","userId":"04076759694923359789"}},"outputId":"7558b8af-61fd-4656-822c-671becbcbeee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(True)"]},"metadata":{},"execution_count":18}]}]}